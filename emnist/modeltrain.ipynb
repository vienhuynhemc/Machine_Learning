{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### We begin my importing the data from the data folder. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import tensorflow as tf\r\n",
    "\r\n",
    "from fg import freeze_graph\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "from mnist import MNIST\r\n",
    "\r\n",
    "mndata = MNIST('data')\r\n",
    "#This will load the train and test data\r\n",
    "X_train, y_train = mndata.load('data/emnist-byclass-train-images-idx3-ubyte',\r\n",
    "                               'data/emnist-byclass-train-labels-idx1-ubyte')\r\n",
    "X_test, y_test = mndata.load('data/emnist-byclass-test-images-idx3-ubyte',\r\n",
    "                             'data/emnist-byclass-test-labels-idx1-ubyte')\r\n",
    "\r\n",
    "\r\n",
    "# Convert data to numpy arrays and normalize images to the interval [0, 1]\r\n",
    "X_train = np.array(X_train) / 255.0\r\n",
    "y_train = np.array(y_train)\r\n",
    "X_test = np.array(X_test) / 255.0\r\n",
    "y_test = np.array(y_test)\r\n",
    "\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.08 GiB for an array with shape (697932, 784) and data type float64",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-5a34e12fb909>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Convert data to numpy arrays and normalize images to the interval [0, 1]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.08 GiB for an array with shape (697932, 784) and data type float64"
     ]
    }
   ],
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Getting Data ready for pre-processing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from matplotlib import pyplot as plt\r\n",
    "#Display a random image\r\n",
    "plt.imshow(X_train[2])\r\n",
    "plt.show"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Y'all can see how an image array looks like. all float values b/w 0 and 1\r\n",
    "m = X_train[2]\r\n",
    "print(m)"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now we perform Image preprocessing. We reverse and rotate all train and test images"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#for train data\r\n",
    "for t in range(10000):\r\n",
    "    X_train[t]=np.transpose(X_train[t])\r\n",
    "    \r\n",
    "#checking\r\n",
    "plt.imshow(X_train[0])\r\n",
    "plt.show\r\n",
    "\r\n",
    "#for test data  chuyển vị\r\n",
    "for t in range(5000):\r\n",
    "    X_test[t]=np.transpose(X_test[t])\r\n",
    "\r\n",
    "#checking\r\n",
    "plt.imshow(X_test[1])\r\n",
    "plt.show\r\n",
    "\r\n",
    "print('Process Complete: Rotated and reversed test and train images!')"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Checking the last train image, just to be sure!\r\n",
    "m = X_train[697931]\r\n",
    "plt.imshow(m)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reshaping train and test data again for input into model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 784,1)\r\n",
    "X_test = X_test.reshape(X_test.shape[0], 784,1)"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creation of model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from keras.models import Sequential\r\n",
    "from keras import optimizers\r\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Dropout, Flatten, Dense, Reshape, LSTM\r\n",
    "from keras import backend as K\r\n",
    "from keras.constraints import maxnorm\r\n",
    "def resh(ipar):\r\n",
    "    opar = []\r\n",
    "    for image in ipar:\r\n",
    "        opar.append(image.reshape(-1))\r\n",
    "    return np.asarray(opar)\r\n",
    "\r\n",
    "from keras.utils import np_utils\r\n",
    "\r\n",
    "train_images = X_train.astype('float32')\r\n",
    "test_images = X_test.astype('float32')\r\n",
    "\r\n",
    "train_images = resh(train_images)\r\n",
    "test_images = resh(test_images)\r\n",
    "\r\n",
    "\r\n",
    "train_labels = np_utils.to_categorical(y_train, 62)\r\n",
    "test_labels = np_utils.to_categorical(y_test, 62)\r\n",
    "\r\n",
    "\r\n",
    "K.set_learning_phase(1)\r\n",
    "\r\n",
    "model = Sequential()\r\n",
    "\r\n",
    "model.add(Reshape((28,28,1), input_shape=(784,)));\r\n",
    "\r\n",
    "#add the layer below for an accuracy of 89%.(Training time - over 20 hours)\r\n",
    "#model.add(Convolution2D(32, (5,5), input_shape=(28,28,1),\r\n",
    "                             #activation='relu',padding='same', kernel_constraint=));\r\n",
    "model.add(Convolution2D(32, (5,5),activation='relu'));\r\n",
    "\r\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "model.add(Flatten())\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "#model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\r\n",
    "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)));\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "model.add(Dropout(0.5));\r\n",
    "\r\n",
    "model.add(Dense(62, activation='softmax'));\r\n",
    "\r\n",
    "#opt = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\r\n",
    "#opt = optimizers.Adadelta()\r\n",
    "opt = optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0);\r\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy']);"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training of model and evaluation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(model.summary());\r\n",
    "history = model.fit(train_images,train_labels,validation_data=(test_images, test_labels), batch_size=128, epochs=5);"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#evaluating model on test data. will take time\r\n",
    "scores = model.evaluate(test_images,test_labels, verbose = 0);\r\n",
    "print(\"Accuracy: %.2f%%\"%(scores[1]*100));"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating model history graphs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(history.history.keys());\r\n",
    "# summarize history for accuracy\r\n",
    "plt.plot(history.history['acc']);\r\n",
    "plt.plot(history.history['val_acc']);\r\n",
    "plt.title('Model Accuracy');\r\n",
    "plt.ylabel('Accuracy');\r\n",
    "plt.xlabel('Epoch');\r\n",
    "plt.legend(['Train', 'Test'], loc='upper left');\r\n",
    "plt.grid();\r\n",
    "plt.show();\r\n",
    "# summarize history for loss\r\n",
    "plt.plot(history.history['loss']);\r\n",
    "plt.plot(history.history['val_loss']);\r\n",
    "plt.title('Model loss');\r\n",
    "plt.ylabel('Loss');\r\n",
    "plt.xlabel('Epoch');\r\n",
    "plt.legend(['Train', 'Test'], loc='upper left');\r\n",
    "plt.grid();\r\n",
    "plt.show();"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "objects = ('RMSDrop', 'Adam', 'Adamax', 'SGD', 'Adadelta');\r\n",
    "y_pos = np.arange(len(objects));\r\n",
    "performance = [86.2,85.39,89.53,84.29,87.11];\r\n",
    " \r\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5);\r\n",
    "plt.xticks(y_pos, objects);\r\n",
    "plt.ylabel('Accuracy');\r\n",
    "plt.title('Optimizers');\r\n",
    "plt.ylim(50,100);\r\n",
    "plt.show();"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Freezing the graph for android Import"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "frozen_graph = freeze_graph(K.get_session(), output_names=[model.output.op.name]);\r\n",
    "tf.train.write_graph(frozen_graph,'.','C:/Users/84168/PycharmProjects/amnist/PBfile8953.pb',as_text=False);\r\n",
    "print(model.input.op.name);\r\n",
    "print(model.output.op.name);"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predicting a single image using the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "m = X_test[258].reshape(28,28);\r\n",
    "plt.imshow(m);\r\n",
    "plt.show;\r\n",
    "print('prediction: '+str(model.predict_classes(X_test[258].reshape(1,784))));"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Saving the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from keras.models import load_model\r\n",
    "from keras.models import model_from_json\r\n",
    "\r\n",
    "model_json = model.to_json();\r\n",
    "with open(\"models.json\", \"w\") as json_file:\r\n",
    "    json_file.write(model_json);\r\n",
    "\r\n",
    "#saves the model info as json file\r\n",
    "\r\n",
    "model.save_weights(\"models.h5\")\r\n",
    "# Creates a HDF5 file 'model.h5'"
   ],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# For usage of this model to predict words, open segment.ipynb"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('base': conda)"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "1196f9ba081f55f069e7debc0e337ad2ff49b2f14b74d30947eb8ea3e5b0572e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}